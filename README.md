Professional Summary
Results-driven Data Scientist with 8 years of professional experience, including 5 years of hands-on expertise in AI/ML, Natural Language Processing (NLP), and document intelligence, complemented by 3 years of experience in construction design across cross-functional and client-facing environments. Skilled in designing, developing, and deploying end-to-end machine learning solutions aligned with business goals in regulated domains such as healthcare, finance, and service sectors.
•	Experience in data science, AI/ML, and natural language processing (NLP), specializing in document-level data extraction and retrieval systems.
•	Developed and deployed advanced information extraction pipelines from diverse document types including PDFs, scanned forms, contracts, and reports using OCR, NLP, and rule-based systems.
•	Built scalable and modular retrieval systems using LangChain, FAISS, and HuggingFace embeddings, enabling real-time document search and semantic querying.
•	Proficient in technical design documentation, system architecture planning, and contributing to codebase through peer code reviews and documentation best practices.
•	Experienced in developing automated data validation rules, anomaly detection, and logic for ensuring data integrity and compliance with internal and external standards.
•	Strong programming proficiency in Python (Pandas, NumPy, PyTorch, TensorFlow), SQL, and API integrations, supporting high-performance backend data processing.
•	Designed and executed technical proof-of-concept (PoC) projects for information extraction use cases in regulated environments including healthcare and finance.
•	Led cross-functional collaborations with engineering, IT, and data governance teams to align extraction workflows with compliance, user needs, and system integration.
Skilled in deploying Retrieval-Augmented Generation (RAG) architectures to dynamically enhance document processing workflows with real-time knowledge injection.
•	Passionate about scalable AI architecture, continuous model evaluation, and contributing to a culture of innovation, documentation, and knowledge sharing.
•	Conducted advanced EDA using Ollama and leveraged Mistral for uncovering complex data insights and relationships, significantly enhancing data-driven.
Technical Skills
Programming & Databases: Python, SQL, MySQL
Machine Learning: Regression (Linear, Gradient Descent, SGD, BGD, Ridge, Lasso, Polynomial), Classification (Logistic Regression, SVM, Decision Tree, Random Forest, k-Nearest Neighbors, Naive Bayes, Multiclass), Clustering (K-Means, Hierarchical, PCA, DBSCAN), Anomaly Detection
Deep Learning: Artificial Neural Networks (ANN), Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN)
NLP & Generative AI: Text Summarization, Tokenization, Lemmatization, Named Entity Recognition (Spacy), Sentiment Analysis, Hugging Face Transformers, LangChain, OpenAI APIs, Retrieval-Augmented Generation (RAG), Prompt Engineering, PEFT, LoRA, OCR
Data Handling & Analysis: Data Extraction, Data Cleaning, Data Exploration, Feature Engineering, Pandas, NumPy, Excel
Data Visualization: Power BI, Tableau, Matplotlib, Seaborn, Plotly
MLOps & Deployment: AWS (SageMaker, Lambda, S3, API Gateway), GCP (Vertex AI, BigQuery, Cloud Storage, Cloud Run, GKE), MLflow, Kubeflow, Docker, FastAPI, Flask, Streamlit, Jenkins, Logging & Monitoring (Grafana, GCP Monitoring)




Professional Experience
Sr. Data Analyst/AI engineer | TLB Enterprise Inc (Full time)				July 2025 to Present
Case Summarization & Resolution Quality Analysis & MLOps Deploment:
•	Scope was to create an automation script to evaluate Semantic similarity (Quality Analysis) using LLAJ, Cosine Similarity.
•	score using NLP methods like Bert-Score, Microsoft/Deberta Sentence Transformers and Auto Tokenizers and deploy with GCP. 
•	Created a Python script with configuration file and envs for automation. 
•	Applied Similarity Score between Human Created Solution for a Tickets and LLM generated solution for the tickets. 
•	Fine Tuned LLM models (GPT, Llama, Mistral and other Transformer models) with customers and domain specific data to improvise the output quality. 
•	Optimized the model performance to choose best HPT metrics with Bayesian Search Optimizer.
•	Stored the script in and config files in Github with version enabled and triggered using GCP Cloud Run.
•	Developed the Data and Model Pipelines using Kubeflow (Kubernetes) and Docker towards MLOps procedure.

Data Scientist| Aariv Technologies (C2C)							Mar 2025 to June 2025
Demand Forecasting & Predictive Analytics Platform
•	Theme of the project is to develop demand forecasting techniques and other Analytical service methods to provide best services to clients. 
•	Building the dynamic method of Demand Forecasting functions with multiple Time series analysis methods(ARIMA, Prophet, LSTM, MA) along with Exogenous(external factors) with every new update which can improve the accuracy of product output. 
•	Feature extraction, analyze and predict the delay of flights,roadways, which can help to logistics to take quick decisions in mode transportation. 
•	Worked closely with Business to build sales forecasting models to enhance future growth of organization. Developed a demand forecasting tool. 
•	Deployed the models using Vertex AI. 

Data Analyst | CloudOne inc (C2C)							Sep 2024 to Mar 2025
Document Digitization and Information Extraction System 
•	Applied Optical character recognition (OCR) technique using libraries Pytesseract, EasyOCR to extract data (text recognition) from Images and PDF files and formatted the data into structured manner using Python, Spacy NER (Name entity recognition). 
•	Extract and Summarize the Tables and PDF file content using Docling and GPT tools with effective Prompts.

Research Volunteer | University of Arkansas at Little Rock 					Jan 23 – May24
Project: AI-Powered Exploratory Data Analysis (EDA) Platform
•	Engineered an LLM-powered EDA automation tool using Mistral and Python, reducing manual data analysis through automated insights and dynamic visualizations.
•	Built a Streamlit to enable non-technical users to upload datasets and generate AI-driven reports with missing value imputation, outlier detection, and natural language explanations of statistical patterns.
•	Integrated local LLM deployment with GPU acceleration to eliminate reliance on cloud APIs.
•	Automated data preprocessing pipelines (median/mode imputation) and correlation analysis, accelerating project kickoffs.
•	Featured in internal tech talks for enabling LLM Model workflows, including GenAI-enhanced feature engineering and RAG-based data Q&A.
Project: Intelligent Document Retrieval & Q&A System with LangChain
•	Engineered a real-time document search and question-answering system using LangChain, FAISS, Milvus, and LLaMA 3 for semantic retrieval across large unstructured datasets.
•	Integrated a Retrieval-Augmented Generation (RAG) framework to enhance response accuracy using contextual knowledge from enterprise documents.
•	Designed and deployed context-aware query handlers to improve relevance of user queries and response quality.
•	Optimized data indexing and vector storage with FAISS and Milvus, improving search latency and scalability.
•	Ensured end-to-end pipeline security and privacy compliance, implementing secure access controls for sensitive document handling.
•	Developed a clean, intuitive UI interface for internal users, expanding system accessibility and cross-departmental adoption.
•	Conducted performance benchmarking and deployed feedback loops for continuous model improvement.

AEDBM consultants, Hyderabad, India								July19 – May22
Role: Engineering & Data Analyst
•	Kitex Garments Limited is children’s apparel manufacturing and the world’s second-largest children’s wear producer, supporting 5,000+ employees and global retail giant with scaling operations internationally with USA and UK.
•	Applied Optical character recognition (OCR) technique using libraries Pytesseract, PyOCR to extract data (text recognition) from Images and PDF files and formatted the data into structured manner using Python, Spacy NER (Name entity recognition). 
•	Extract and Summarize the Tables and PDF file content and applied analysis for term reports.
•	Optimized production workflows by analysing order processing times and identifying manufacturing bottlenecks.
•	Built Power BI dashboards to monitor key factory metrics and data exploration analysis.
•	Building the dynamic method of Demand Forecasting functions with multiple Time series analysis methods (ARIMA, Prophet, LSTM, MA) along with Exogenous (external factors) with every new update which can improve the accuracy of product output. 
•	Feature extraction, analyze and predict the delay of flights, roadways, which can help to logistics to take quick decisions in mode transportation. 
Engineer-Designs, Hyderabad, India								Sep2016 – June2019
Role: Engineer - Designs
•	Designed RCC and Steel buildings in commercial, residential, Industrial and Defence sectors using EATBS, STAAD pro, SAFE, AutoCAD, MS Excel etc.
•	Coordination with cross functional teams to deliver the project on time and with client satisfactory.
•	Attending meetings with client, taking notes and preparing MOM, sending to cross functional teams.
•	
EDUCATION:
•	Master’s in Information Quality - University of Arkansas at Little Rock | GPA: 3.54 (Aug 2022 – May 2024).
•	B.Tech in Civil Engineering – JNTUA, India | 71% | 2010-2014.
CERTIFICATIONS:
•	Microsoft Certified: Power BI Data Analyst Associate
